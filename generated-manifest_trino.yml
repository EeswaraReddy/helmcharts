---
# Source: trino/templates/configmap-catalog.yaml
apiVersion: v1
kind: ConfigMap
metadata:
  name: chimera-trino-adhoc-catalog
  namespace: default
  labels:
    helm.sh/chart: trino-1.37.0
    app.kubernetes.io/name: chimera-trino-adhoc
    app.kubernetes.io/instance: chimera
    app.kubernetes.io/version: "470"
    app.kubernetes.io/managed-by: Helm
    app.kubernetes.io/component: catalogs
data:
  chimera_db.properties: |
    connector.name=postgresql
    connection-url=jdbc:postgresql://localhost:5432/chimera_db
    connection-user=chimera_user
    connection-password=chimera_pass
  datahub_db.properties: |
    connector.name=postgresql
    connection-url=jdbc:postgresql://localhost:5432/datahub_db
    connection-user=datahub_user
    connection-password=datahub_pass
  keycloak_db.properties: |
    connector.name=postgresql
    connection-url=jdbc:postgresql://localhost:5432/keycloak_db
    connection-user=keycloak_user
    connection-password=keycloak_pass
  superset_db.properties: |
    connector.name=postgresql
    connection-url=jdbc:postgresql://localhost:5432/superset_db
    connection-user=superset_user
    connection-password=superset_pass
  tpcds.properties: |
    connector.name=tpcds
    tpcds.splits-per-node=4
    
  tpch.properties: |
    connector.name=tpch
    tpch.splits-per-node=4
    
  vault_db.properties: |
    connector.name=postgresql
    connection-url=jdbc:postgresql://localhost:5432/vault_db
    connection-user=vault_user
    connection-password=vault_pass
---
# Source: trino/templates/configmap-coordinator.yaml
apiVersion: v1
kind: ConfigMap
metadata:
  name: chimera-trino-coordinator-adhoc
  namespace: default
  labels:
    helm.sh/chart: trino-1.37.0
    app.kubernetes.io/name: chimera-trino-adhoc
    app.kubernetes.io/instance: chimera
    app.kubernetes.io/version: "470"
    app.kubernetes.io/managed-by: Helm
    app.kubernetes.io/component: coordinator
data:
  node.properties: |
    node.environment=production
    node.data-dir=/data/trino
    plugin.dir=/usr/lib/trino/plugin

  jvm.config: |
    -server
    -agentpath:/usr/lib/trino/bin/libjvmkill.so
    -Xmx8G
    -XX:+UseG1GC
    -XX:G1HeapRegionSize=32M
    -XX:+ExplicitGCInvokesConcurrent
    -XX:+HeapDumpOnOutOfMemoryError
    -XX:+ExitOnOutOfMemoryError
    -XX:-OmitStackTraceInFastThrow
    -XX:ReservedCodeCacheSize=512M
    -XX:PerMethodRecompilationCutoff=10000
    -XX:PerBytecodeRecompilationCutoff=10000
    -Djdk.attach.allowAttachSelf=true
    -Djdk.nio.maxCachedBufferSize=2000000
    # Allow loading dynamic agent used by JOL
    -XX:+EnableDynamicAgentLoading
  
    # https://bugs.openjdk.org/browse/JDK-8329528
    -XX:+UnlockDiagnosticVMOptions
    -XX:G1NumCollectionsKeepPinned=10000000

  config.properties: |
    coordinator=true
    node-scheduler.include-coordinator=false
    http-server.http.port=8080
    query.max-memory=4GB
    query.max-memory-per-node=1GB
    discovery.uri=http://localhost:8080
  exchange-manager.properties: |
    exchange-manager.name=filesystem
    exchange.base-directories=/tmp/trino-local-file-system-exchange-manager

  log.properties: |
    io.trino=INFO
---
# Source: trino/templates/configmap-coordinator.yaml
apiVersion: v1
kind: ConfigMap
metadata:
  name: chimera-trino-adhoc-schemas-volume-coordinator
  namespace: default
  labels:
    helm.sh/chart: trino-1.37.0
    app.kubernetes.io/name: chimera-trino-adhoc
    app.kubernetes.io/instance: chimera
    app.kubernetes.io/version: "470"
    app.kubernetes.io/managed-by: Helm
    app.kubernetes.io/component: coordinator
data:
---
# Source: trino/templates/configmap-worker.yaml
apiVersion: v1
kind: ConfigMap
metadata:
  name: chimera-trino-worker-adhoc
  namespace: default
  labels:
    helm.sh/chart: trino-1.37.0
    app.kubernetes.io/name: chimera-trino-adhoc
    app.kubernetes.io/instance: chimera
    app.kubernetes.io/version: "470"
    app.kubernetes.io/managed-by: Helm
    app.kubernetes.io/component: worker
data:
  node.properties: |
    node.environment=production
    node.data-dir=/data/trino
    plugin.dir=/usr/lib/trino/plugin

  jvm.config: |
    -server
    -agentpath:/usr/lib/trino/bin/libjvmkill.so
    -Xmx8G
    -XX:+UseG1GC
    -XX:G1HeapRegionSize=32M
    -XX:+ExplicitGCInvokesConcurrent
    -XX:+HeapDumpOnOutOfMemoryError
    -XX:+ExitOnOutOfMemoryError
    -XX:-OmitStackTraceInFastThrow
    -XX:ReservedCodeCacheSize=512M
    -XX:PerMethodRecompilationCutoff=10000
    -XX:PerBytecodeRecompilationCutoff=10000
    -Djdk.attach.allowAttachSelf=true
    -Djdk.nio.maxCachedBufferSize=2000000
    # Allow loading dynamic agent used by JOL
    -XX:+EnableDynamicAgentLoading
  
    # https://bugs.openjdk.org/browse/JDK-8329528
    -XX:+UnlockDiagnosticVMOptions
    -XX:G1NumCollectionsKeepPinned=10000000

  config.properties: |
    coordinator=false
    http-server.http.port=8080
    query.max-memory=4GB
    query.max-memory-per-node=1GB
    discovery.uri=http://chimera-trino-adhoc:8080
  exchange-manager.properties: |
    exchange-manager.name=filesystem
    exchange.base-directories=/tmp/trino-local-file-system-exchange-manager

  log.properties: |
    io.trino=INFO
---
# Source: trino/templates/configmap-worker.yaml
apiVersion: v1
kind: ConfigMap
metadata:
  name: chimera-trino-adhoc-schemas-volume-worker
  namespace: default
  labels:
    helm.sh/chart: trino-1.37.0
    app.kubernetes.io/name: chimera-trino-adhoc
    app.kubernetes.io/instance: chimera
    app.kubernetes.io/version: "470"
    app.kubernetes.io/managed-by: Helm
    app.kubernetes.io/component: worker
data:
---
# Source: trino/templates/service-coordinator.yaml
apiVersion: v1
kind: Service
metadata:
  name: chimera-trino-adhoc
  namespace: default
  labels:
    helm.sh/chart: trino-1.37.0
    app.kubernetes.io/name: chimera-trino-adhoc
    app.kubernetes.io/instance: chimera
    app.kubernetes.io/version: "470"
    app.kubernetes.io/managed-by: Helm
    app.kubernetes.io/component: coordinator
  annotations:
    {}
spec:
  type: ClusterIP
  ports:
    - port: 8080
      targetPort: http
      protocol: TCP
      name: http
  selector:
    app.kubernetes.io/name: chimera-trino-adhoc
    app.kubernetes.io/instance: chimera
    app.kubernetes.io/component: coordinator
---
# Source: trino/templates/service-worker.yaml
apiVersion: v1
kind: Service
metadata:
  name: chimera-trino-adhoc-worker
  namespace: default
  labels:
    helm.sh/chart: trino-1.37.0
    app.kubernetes.io/name: chimera-trino-adhoc
    app.kubernetes.io/instance: chimera
    app.kubernetes.io/version: "470"
    app.kubernetes.io/managed-by: Helm
    app.kubernetes.io/component: worker
  annotations:
    {}
spec:
  clusterIP: None
  ports:
    - port: 8080
      targetPort: http
      protocol: TCP
      name: http
  selector:
    app.kubernetes.io/name: chimera-trino-adhoc
    app.kubernetes.io/instance: chimera
    app.kubernetes.io/component: worker
---
# Source: trino/templates/deployment-coordinator.yaml
apiVersion: apps/v1
kind: Deployment
metadata:
  name: chimera-trino-coordinator-adhoc
  namespace: default
  labels:
    helm.sh/chart: trino-1.37.0
    app.kubernetes.io/name: chimera-trino-adhoc
    app.kubernetes.io/instance: chimera
    app.kubernetes.io/version: "470"
    app.kubernetes.io/managed-by: Helm
    app.kubernetes.io/component: coordinator
    trino.io/network-policy-protection: disabled
  annotations:
    {}
spec:
  progressDeadlineSeconds: 600
  revisionHistoryLimit: 10
  strategy:
    rollingUpdate:
      maxSurge: 25%
      maxUnavailable: 25%
    type: RollingUpdate
  selector:
    matchLabels:
      app.kubernetes.io/name: chimera-trino-adhoc
      app.kubernetes.io/instance: chimera
      app.kubernetes.io/component: coordinator
  template:
    metadata:
      annotations:
        checksum/catalog-config: 7d211eedbb791fd0361ffa5642bd1253f3776b866e6acc87fccad7b3f9bb1e16
        checksum/coordinator-config: ba28e47e6174d7cb62df86c4c34c84ccd5cff7eaa68218343e46c4bad115687f

      labels:
        helm.sh/chart: trino-1.37.0
        app.kubernetes.io/name: chimera-trino-adhoc
        app.kubernetes.io/instance: chimera
        app.kubernetes.io/version: "470"
        app.kubernetes.io/managed-by: Helm
        app.kubernetes.io/component: coordinator
        trino.io/network-policy-protection: disabled
    spec:
      serviceAccountName: default
      securityContext:
        runAsGroup: 1000
        runAsUser: 1000
      volumes:
        - name: config-volume
          configMap:
            name: chimera-trino-coordinator-adhoc
        - name: catalog-volume
          configMap:
            name: chimera-trino-adhoc-catalog
        - name: schemas-volume
          configMap:
            name: chimera-trino-adhoc-schemas-volume-coordinator
      terminationGracePeriodSeconds: 30
      containers:
        - name: trino-coordinator
          image: trinodb/trino:470
          imagePullPolicy: IfNotPresent
          securityContext:
            allowPrivilegeEscalation: false
            capabilities:
              drop:
              - ALL
          env:
            []
          envFrom:
            []
          volumeMounts:
            - mountPath: /etc/trino
              name: config-volume
            - mountPath: /etc/trino/catalog
              name: catalog-volume
            - mountPath: /etc/trino/schemas
              name: schemas-volume
          ports:
            - name: http
              containerPort: 8080
              protocol: TCP
          livenessProbe:
            httpGet:
              path: /v1/info
              port: http
            initialDelaySeconds: 20
            periodSeconds: 10
            timeoutSeconds: 5
            failureThreshold: 6
            successThreshold: 1
          readinessProbe:
            exec:
              command: [/usr/lib/trino/bin/health-check]
            initialDelaySeconds: 20
            periodSeconds: 10
            timeoutSeconds: 5
            failureThreshold: 6
            successThreshold: 1
          lifecycle:
            preStop:
              exec:
                command:
                - /bin/sh
                - -c
                - sleep 120
          resources:
            {}
---
# Source: trino/templates/deployment-worker.yaml
apiVersion: apps/v1
kind: Deployment
metadata:
  name: chimera-trino-worker-adhoc
  namespace: default
  labels:
    helm.sh/chart: trino-1.37.0
    app.kubernetes.io/name: chimera-trino-adhoc
    app.kubernetes.io/instance: chimera
    app.kubernetes.io/version: "470"
    app.kubernetes.io/managed-by: Helm
    app.kubernetes.io/component: worker
    trino.io/network-policy-protection: disabled
  annotations:
    {}
spec:
  progressDeadlineSeconds: 600
  revisionHistoryLimit: 10
  strategy:
    rollingUpdate:
      maxSurge: 25%
      maxUnavailable: 25%
    type: RollingUpdate
  replicas: 2
  selector:
    matchLabels:
      app.kubernetes.io/name: chimera-trino-adhoc
      app.kubernetes.io/instance: chimera
      app.kubernetes.io/component: worker
  template:
    metadata:
      annotations:
        checksum/catalog-config: 7d211eedbb791fd0361ffa5642bd1253f3776b866e6acc87fccad7b3f9bb1e16
        checksum/worker-config: 8c964581bd828a3b2a39be9030a1d1ea03c0b326dff09ede4ccee4bd8a35f03c
      labels:
        helm.sh/chart: trino-1.37.0
        app.kubernetes.io/name: chimera-trino-adhoc
        app.kubernetes.io/instance: chimera
        app.kubernetes.io/version: "470"
        app.kubernetes.io/managed-by: Helm
        app.kubernetes.io/component: worker
        trino.io/network-policy-protection: disabled
    spec:
      serviceAccountName: default
      securityContext:
        runAsGroup: 1000
        runAsUser: 1000
      volumes:
        - name: config-volume
          configMap:
            name: chimera-trino-worker-adhoc
        - name: catalog-volume
          configMap:
            name: chimera-trino-adhoc-catalog
        - name: schemas-volume
          configMap:
            name: chimera-trino-adhoc-schemas-volume-worker
      terminationGracePeriodSeconds: 30
      containers:
        - name: trino-worker
          image: trinodb/trino:470
          imagePullPolicy: IfNotPresent
          securityContext:
            allowPrivilegeEscalation: false
            capabilities:
              drop:
              - ALL
          env:
            []
          envFrom:
            []
          volumeMounts:
            - mountPath: /etc/trino
              name: config-volume
            - mountPath: /etc/trino/catalog
              name: catalog-volume
            - mountPath: /etc/trino/schemas
              name: schemas-volume
          ports:
            - name: http
              containerPort: 8080
              protocol: TCP
          livenessProbe:
            httpGet:
              path: /v1/info
              port: http
            initialDelaySeconds: 20
            periodSeconds: 10
            timeoutSeconds: 5
            failureThreshold: 6
            successThreshold: 1
          readinessProbe:
            exec:
              command: [/usr/lib/trino/bin/health-check]
            initialDelaySeconds: 20
            periodSeconds: 10
            timeoutSeconds: 5
            failureThreshold: 6
            successThreshold: 1
          lifecycle:
            preStop:
              exec:
                command:
                - /bin/sh
                - -c
                - 'curl -v -X PUT -d ''"SHUTTING_DOWN"'' -H "Content-type: application/json" http://localhost:8080/v1/info/state'
          resources:
            {}
---
# Source: trino/templates/tests/test-connection.yaml
apiVersion: v1
kind: Pod
metadata:
  name: chimera-trino-adhoc-test-connection
  labels:
    helm.sh/chart: trino-1.37.0
    app.kubernetes.io/name: chimera-trino-adhoc
    app.kubernetes.io/instance: chimera
    app.kubernetes.io/version: "470"
    app.kubernetes.io/managed-by: Helm
    app.kubernetes.io/component: test
    test: connection
  annotations:
    "helm.sh/hook": test
spec:
  containers:
    - name: cli
      image: trinodb/trino:470
      command: ['trino']
      args:
      - trino://chimera-trino-adhoc:8080
      - --user=admin
      - --debug
      - --execute=SELECT COUNT(*) FROM tpch.tiny.nation
      - --no-progress
  restartPolicy: Never
